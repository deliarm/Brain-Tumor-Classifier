{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a379f-f3e2-4d77-892a-1c2bb999edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd22f4a1-0404-4b08-b910-d4e7119a5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8093ad-ff64-4a3f-abb2-2ce491e554a8",
   "metadata": {},
   "source": [
    "### Image preprocessing ###\n",
    "\n",
    "The original images contain black backgrounds of various sizes. Feeding these raw images into our model would result in lower accuracy as the model could pickup on background size as a feature for determining tumor type. To combat this, we can crop the images using the cv2 library. \n",
    "\n",
    "Below is an example of how we crop images from start to finish, as outlined in crop_image().\n",
    "\n",
    "|Step 0 ) Original Image      |Step 1) Thresh Image                 |Step 2) Erode Image            | Step 3) Dilate Image         |Step 4) Crop Original Image |\n",
    "|-----------------------------|-------------------------------------|-------------------------------|------------------------------|----------------------------|\n",
    "| ![org](utils/original.jpg)  |![thr](utils/after_thresholding.jpg) |![ero](utils/after_eroding.jpg)|![dil](utils/after_dilate.jpg)|![cro](utils/after_crop.jpg)|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5b479eec-e9d3-460e-921e-6d3c62caab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img):\n",
    "    grayscale_image = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    _,thresholded_image = cv2.threshold(grayscale_image, 10, 255, cv2.THRESH_BINARY)\n",
    "    eroded_image = cv2.erode(thresholded_image, None, iterations=2)\n",
    "    dilated_image = cv2.dilate(eroded_image, None, iterations=2)\n",
    "    \n",
    "    contours = cv2.findContours(dilated_image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    points = max(contours, key=cv2.contourArea) # [[[x_val,y_valval]]]\n",
    "    \n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for point in points:\n",
    "        x_points.append(point[0][0])\n",
    "        y_points.append(point[0][1])\n",
    "\n",
    "    left = min(x_points)\n",
    "    right = max(x_points)\n",
    "    top = min(y_points)\n",
    "    bottom = max(y_points)\n",
    "\n",
    "    cropped_image = img[top:bottom, left:right]\n",
    "    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e85e62d3-6a07-4ecf-9101-854f827ee35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SIZE = 400\n",
    "\n",
    "new_img2 = crop_image(image)\n",
    "new_img2 = cv2.resize(new_img2,(IMG_SIZE,IMG_SIZE))\n",
    "cv2.imwrite(\"test_crop.jpg\",new_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61ab62-ff3b-4c55-8a93-d39ff5e0cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f1b5e-0749-4242-b599-67e761eac0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978fed7-bb39-46c9-9eee-94bb91a21c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab4ce041-59ba-44ca-84b6-0ba5e4f6e15b",
   "metadata": {},
   "source": [
    "### References \n",
    "https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset?resource=download\n",
    "\n",
    "https://github.com/masoudnick/Brain-Tumor-MRI-Classification/blob/main/Preprocessing.py\n",
    "\n",
    "https://docs.opencv.org/4.x/\n",
    "                    \n",
    "https://pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5059ab7-d341-4af9-9bce-7c643a9779cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
